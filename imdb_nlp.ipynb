{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nadh's.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPamPx2oOI+phveVSTk4uWo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djidachahrazed/Semantic-Similarity/blob/master/imdb_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdLwwItpK3xk"
      },
      "source": [
        "#PACKAGES \r\n",
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yH43sQBQ9Mj"
      },
      "source": [
        "#QUESTION1:\r\n",
        "dataFrm = pd.read_csv(r\"/content/IMDB.csv\")  \r\n",
        "dataFrm.columns= [\"review\", \"sentiment\"]\r\n",
        "print(dataFrm.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6gUgHB8Q9Q_"
      },
      "source": [
        "# QUESTION 2:\r\n",
        "#*************QUESTION 2-1**************\r\n",
        "print(dataFrm.sentiment.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cA-Rg-dQ9Un"
      },
      "source": [
        "#************QUESTION 2-2**************\r\n",
        "dataFrm[\"phrase_len\"] = [len(x) for x in dataFrm.review]\r\n",
        "print(dataFrm.head(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCVZOHpKQ9Wt"
      },
      "source": [
        "#************QUESTION 2-3***************\r\n",
        "group = dataFrm.groupby(\"sentiment\")\r\n",
        "#mean: moyenne\r\n",
        "print(\"Taille moyenne pour neg. reviews: \", group.get_group(\"negative\")[\"phrase_len\"].mean())\r\n",
        "print(\"Taille moyenne pour pos. reviews: \", group.get_group(\"positive\")[\"phrase_len\"].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0xBTRcoQ9YV"
      },
      "source": [
        "#************QUESTION 2-4***************\r\n",
        "#loc : Access a group of rows and columns by label(s) or a boolean array.\r\n",
        "dataFrm = dataFrm.loc[ (dataFrm[\"phrase_len\"] > 3) , : ]\r\n",
        "print(dataFrm.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAxCQC8RQ9bX"
      },
      "source": [
        "#************QUESTION 2-5***************\r\n",
        "dataFrm = dataFrm.drop(columns = \"phrase_len\" )\r\n",
        "print(dataFrm.head(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFq02q0esI0T"
      },
      "source": [
        "#Question3\r\n",
        "#------------QUESTION3.1: netoyage de corpus ----------\r\n",
        "# upper to lower\r\n",
        "def wordLowerCase(text):\r\n",
        "    return text.lower()\r\n",
        "def tokenization(text):\r\n",
        "    return (text.split())\r\n",
        "def stopword_elimination(text):\r\n",
        "    listes_words=tokenization(text)\r\n",
        "    new_list=[]\r\n",
        "    for word in listes_words:\r\n",
        "        if word not in stopwords.words(\"english\"):\r\n",
        "            new_list.append(word)\r\n",
        "    return new_list\r\n",
        "def stemming(text):\r\n",
        "    port=PorterStemmer()\r\n",
        "    print(\"\\nstemming\")\r\n",
        "    return \" \".join([port.stem(i)for i in text.split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib_nBItDQdTP"
      },
      "source": [
        "dataFrm[\"review\"] = dataFrm[\"review\"].str.lower().str.split()\r\n",
        "print(dataFrm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni3OX0j3sl8T"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z4RLAlmsiHj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B9msdCtsI5t"
      },
      "source": [
        "stop = stopwords.words('english')\r\n",
        "dataFrm[\"review\"].apply(lambda x: [item for item in x if item not in stop])\r\n",
        "print(dataFrm.head(10))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWq2SP3Nsvte"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\r\n",
        "\r\n",
        "stemmer = PorterStemmer()\r\n",
        "def stem_words(text):\r\n",
        "  return \" \".join([stemmer.stem(word) for word in text])\r\n",
        "\r\n",
        "dataFrm[\"review\"] =dataFrm[\"review\"].apply(lambda text: stem_words(text))\r\n",
        "print(dataFrm[\"review\"].head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfv-fLwNWocS"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buJFPSJDspB6"
      },
      "source": [
        "#QUESTION4\r\n",
        "#tf_idf\r\n",
        "import sklearn\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,2))\r\n",
        "text_count_matrix = tfidf.fit_transform(dataFrm.review)\r\n",
        "#print(text_count_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wav_sanspHX"
      },
      "source": [
        "#QUESTION5\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(text_count_matrix, dataFrm.sentiment, test_size=0.30, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbbNIZ3qsI7h"
      },
      "source": [
        "#QUESTION6\r\n",
        "# let's use Naive Bayes classifier and fit our model:\r\n",
        "from sklearn.naive_bayes import MultinomialNB \r\n",
        "MNB = MultinomialNB()\r\n",
        "MNB.fit(x_train, y_train)\r\n",
        "#4. Evaluating the model\r\n",
        "from sklearn import metrics\r\n",
        "accuracy_score = metrics.accuracy_score(MNB.predict(x_test), y_test)\r\n",
        "print(\"accuracy_score = \" + str('{:04.2f}'.format(accuracy_score*100))+\" %\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf6JPqtnsI_m"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "\r\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, MNB.predict(x_test),target_names=['Negative','Positive']))\r\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, MNB.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQeD91DaaMBA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}